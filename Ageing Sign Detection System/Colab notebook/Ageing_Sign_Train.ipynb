{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ageing_Sign_Train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMR7EL9KtTwmlKSsTm3zuS3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9-2LR05TRMR3"},"source":["### Ageing_Sign_Train"]},{"cell_type":"code","metadata":{"id":"330v306IIMdh"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator # for image augmentation\n","from tensorflow.keras.optimizers import Adam # optimizer\n","from tensorflow.keras.preprocessing.image import img_to_array # converting image to array\n","from tensorflow.keras.models import Sequential # forward flowing network\n","from tensorflow.keras.layers import Dense, MaxPooling2D, Flatten, Dropout, Conv2D # dense-fully connected nodes,dropout-# of nodes to block\n","from tensorflow.keras.applications import EfficientNetB0 #efficientNet model B0 (img size 244, 244, 3)\n","from sklearn.preprocessing import MultiLabelBinarizer # for multilabel classification\n","from sklearn.model_selection import train_test_split # splitting the data into training and testing\n","import matplotlib.pyplot as plt # for plotting training & accuracy graph \n","from imutils import paths # to work on directories\n","import tensorflow as tf\n","import numpy as np\n","import random\n","import cv2\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gm1v5Tja-Guc"},"source":["tf.test.gpu_device_name()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VZwLGmB-ZxC"},"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrPZ3PPFIOZ7"},"source":["#Defining Constants\n","EPOCHS = 20 # no. of iterations the neural model trains\n","INIT_LR = 1e-3 # default value of Adam optimizer(0.001)\n","BS = 25 # batch_size\n","IMAGE_DIMS = (244, 244, 3) # Image dimensions for EfficientNetB0\n","tf.compat.v1.disable_eager_execution() # synchronization(optional)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDFamng1Id2b"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-eRKSd_Ilhn"},"source":["###########################################PATH TO dataset FOLDER COMES HERE####\n","imagePaths = sorted(list(paths.list_images(\"/content/gdrive/My Drive/dataset/\")))# gathering all image paths\n","random.seed(42) # specifying a random no. to randomize the directories\n","random.shuffle(imagePaths)\n","\n","data = []\n","labels = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywUcqyYBQmVr"},"source":["for imagePath in imagePaths: #for every directory we're traversing all the images\n","  image = cv2.imread(imagePath) # reading the image\n","  image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0])) # resizing the image to match efficientNetB0 conditions\n","  image = img_to_array(image) # converting the resized image to array\n","  data.append(image)\n","\n","  l = label = imagePath.split(os.path.sep)[-2].split(\"_\") # splitting the list of labels from the directory name\n","  labels.append(l)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9-uTSVua_EJ"},"source":["data = np.array(data, dtype=\"float\")/255.0 # preprocessing(normalization) the image to get values between 0 and 1 to ease computation burden\n","labels = np.array(labels, dtype=object) # converting the label to an array\n","print(\"[INFO] data matrix: {} images ({:.2f} MB)\".format(len(imagePaths), data.nbytes / (1024 * 1000.0))) # gathering info about the whole data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kf-pyG-8e1Tr"},"source":["print(\"[INFO] class labels: \")\n","mlb = MultiLabelBinarizer() # initializing the MultiLabelBinarizer class\n","labels = mlb.fit_transform(labels) # this class converts all the labels into distinct values\n","\n","for (i, label) in enumerate(mlb.classes_): # printing the labels (total 4)\n","    print(\"{}. {}\".format(i+1, label))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sa9iTBY3e9T5"},"source":["(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42) # splitting data into training & testing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EFm7Mxe7gEDL"},"source":["trainX.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVbCFRwsgN3H"},"source":["testX.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TbEDp4bMgRcI"},"source":["trainY.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fIId7qygSXI"},"source":["testY.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zDaS0RPgTKo"},"source":["dataGen = ImageDataGenerator(\n","    rotation_range=25,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\"\n",") # creating modified images, by rotating, shifting, zooming, shearing or flipping the image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CeMv4Lv0gyEq"},"source":["dataGen.fit(trainX) # applying the augmentation the training images only"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MibUtXXLhLne"},"source":["#Specifying the architecture of our neural network\n","conv_base = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=IMAGE_DIMS)#input layer\n","model = Sequential()\n","model.add(conv_base)\n","model.add(Dropout(rate=0.4))\n","model.add(Flatten())\n","model.add(Dense(len(mlb.classes_), activation=\"sigmoid\"))# output layer sigmoid is more effective for multilabel classification\n","conv_base.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXGG_139hTfY"},"source":["opt = Adam(learning_rate=INIT_LR, decay=INIT_LR/EPOCHS) #optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IPwhw3hMiySj"},"source":["#compiling the model\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]) # binary_crossentropy is a loss function for multi label classification"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twWnXlnOi-AT"},"source":["#training the model\n","print(\"[INFO] training the network...\")\n","H=model.fit(\n","    dataGen.flow(trainX, trainY, batch_size=BS),\n","    validation_data=(testX, testY),\n","    epochs=30\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwI1h_Go1qBT"},"source":["plt.style.use(\"ggplot\")\n","plt.figure()\n","N = 30\n","plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n","#plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"upper left\")\n","############PATH WHERE YOU WANT TO SAVE THE graph FILE COMES HERE##\n","plt.savefig(\"/content/gdrive/My Drive/model_weights/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIWxqLDJjfaU"},"source":["#saving the model and weights\n","model_json = model.to_json()\n","##########PATH WHERE YOU WHAT TO SAVE THE model.json FILE COMES HERE########\n","with open(\"path_to_folder_where_you_want_to_save_the_model\"+\"model.json\", \"w\") as file:\n","  file.write(model_json)\n","  file.close()\n","###################PATH WHERE YOU WANT TO SAVE THE weights.h5 FILE COMES HERE##\n","model.save_weights(\"path_to_folder_where_you_want_to_save_the_weights\"+\"weights.h5\")\n","print(\"Model Saved Successfully!!\")"],"execution_count":null,"outputs":[]}]}
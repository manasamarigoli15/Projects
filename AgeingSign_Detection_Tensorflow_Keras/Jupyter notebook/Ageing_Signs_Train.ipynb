{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c3ddd6",
   "metadata": {},
   "source": [
    "### Ageing_Sign_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfcda69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # for image augmentation\n",
    "from tensorflow.keras.optimizers import Adam # optimizer\n",
    "from tensorflow.keras.preprocessing.image import img_to_array # converting image to array\n",
    "from tensorflow.keras.models import Sequential # forward flowing network\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Flatten, Dropout, Conv2D # dense-fully connected nodes,dropout-# of nodes to block\n",
    "from tensorflow.keras.applications import EfficientNetB0 #efficientNet model B0 (img size 244, 244, 3)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # for multilabel classification\n",
    "from sklearn.model_selection import train_test_split # splitting the data into training and testing\n",
    "import matplotlib.pyplot as plt # for plotting training & accuracy graph \n",
    "from imutils import paths # to work on directories\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Constants\n",
    "EPOCHS = 20 # no. of iterations the neural model trains\n",
    "INIT_LR = 1e-3 # default value of Adam optimizer(0.001)\n",
    "BS = 25 # batch_size\n",
    "IMAGE_DIMS = (244, 244, 3) # Image dimensions for EfficientNetB0\n",
    "tf.compat.v1.disable_eager_execution() # synchronization(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc23f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################PATH TO dataset FOLDER COMES HERE############\n",
    "imagePaths = sorted(list(paths.list_images(\"path to dataset\")))# gathering all image paths\n",
    "random.seed(42) # specifying a random no. to randomize the directories\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01492f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths: #for every directory we're traversing all the images\n",
    "  image = cv2.imread(imagePath) # reading the image\n",
    "  image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0])) # resizing the image to match efficientNetB0 conditions\n",
    "  image = img_to_array(image) # converting the resized image to array\n",
    "  data.append(image)\n",
    "\n",
    "  l = label = imagePath.split(os.path.sep)[-2].split(\"_\") # splitting the list of labels from the directory name\n",
    "  labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\")/255.0 # preprocessing(normalization) the image to get values between 0 and 1 to ease computation burden\n",
    "labels = np.array(labels, dtype=object) # converting the label to an array\n",
    "print(\"[INFO] data matrix: {} images ({:.2f} MB)\".format(len(imagePaths), data.nbytes / (1024 * 1000.0))) # gathering info about the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] class labels: \")\n",
    "mlb = MultiLabelBinarizer() # initializing the MultiLabelBinarizer class\n",
    "labels = mlb.fit_transform(labels) # this class converts all the labels into distinct values\n",
    "\n",
    "for (i, label) in enumerate(mlb.classes_): # printing the labels (total 4)\n",
    "    print(\"{}. {}\".format(i+1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a014aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42) # splitting data into training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442cd904",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ") # creating modified images, by rotating, shifting, zooming, shearing or flipping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen.fit(trainX) # applying the augmentation the training images only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the architecture of our neural network\n",
    "conv_base = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=IMAGE_DIMS)#input layer\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(mlb.classes_), activation=\"sigmoid\"))# output layer sigmoid is more effective for multilabel classification\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR/EPOCHS) #optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]) # binary_crossentropy is a loss function for multi label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "print(\"[INFO] training the network...\")\n",
    "H=model.fit(\n",
    "    dataGen.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b2cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting and saving the graph to analyse training and testing(optional)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = 30\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "#plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.savefig(\"/content/gdrive/My Drive/model_weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model and weights\n",
    "model_json = model.to_json()\n",
    "#########PATH WHERE WE WANT TO SAVE THE model.json FILE COMES HERE################\n",
    "with open(\"path to directory where you want to save model\" + \"model.json\", \"w\") as file:\n",
    "  file.write(model_json)\n",
    "  file.close()\n",
    "###################PATH WHERE WE WANT TO SAVE THE weights.h5 FILE COMES HERE############\n",
    "model.save_weights(\"path to directory where you want to save weights\"+\"weights.h5\")\n",
    "print(\"Model Saved Successfully!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1ec6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
